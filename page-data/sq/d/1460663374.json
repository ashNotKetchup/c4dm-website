{"data":{"about":{"html":"<p>The <em><strong>Centre for Digital Music</strong></em> is a world-leading, multidisciplinary research group in the field of music &#x26; audio technology.</p>\n<!-- <p style=\"color: red\">**THIS SEEMS TO BE THE ONLY SUPPORTED WAY OF IMPORTING TWITTER TWEETS IN GATSBY 5 AT THE MOMENT, AFAIK IT MEANS THAT EACH \nTWEET HAS TO BE MANUALLY IMPORTED INTO AN MD FILE...**</p>\n<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">This is what we do: <a href=\"https://t.co/pkyS6IcIUy\">https://t.co/pkyS6IcIUy</a> - an excellent video intro to the wonderful researchers of <a href=\"https://twitter.com/c4dm?ref_src=twsrc%5Etfw\">@c4dm</a>. <a href=\"https://twitter.com/QMEECS?ref_src=twsrc%5Etfw\">@QMEECS</a> <a href=\"https://twitter.com/QMUL?ref_src=twsrc%5Etfw\">@QMUL</a> <a href=\"https://twitter.com/hashtag/research?src=hash&amp;ref_src=twsrc%5Etfw\">#research</a></p>&mdash; C4DM at QMUL (@c4dm) <a href=\"https://twitter.com/c4dm/status/857989625922695173?ref_src=twsrc%5Etfw\">April 28, 2017</a></blockquote> -->","frontmatter":{"title":"About the centre","video":"https://www.youtube.com/embed/Rcbs4NvMFHM","image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/c138fbce66e709a3f503405435de2f2c/354fd/c4dm.png","srcSet":"/static/c138fbce66e709a3f503405435de2f2c/0fc07/c4dm.png 100w,\n/static/c138fbce66e709a3f503405435de2f2c/bc685/c4dm.png 200w,\n/static/c138fbce66e709a3f503405435de2f2c/354fd/c4dm.png 400w,\n/static/c138fbce66e709a3f503405435de2f2c/7ef25/c4dm.png 800w","sizes":"(min-width: 400px) 400px, 100vw"},"sources":[{"srcSet":"/static/c138fbce66e709a3f503405435de2f2c/29e9d/c4dm.webp 100w,\n/static/c138fbce66e709a3f503405435de2f2c/2f9ed/c4dm.webp 200w,\n/static/c138fbce66e709a3f503405435de2f2c/ece87/c4dm.webp 400w,\n/static/c138fbce66e709a3f503405435de2f2c/4bc26/c4dm.webp 800w","type":"image/webp","sizes":"(min-width: 400px) 400px, 100vw"}]},"width":400,"height":60}}}}},"projects":{"nodes":[{"fields":{"slug":"/projects/cdtdata"},"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#080838","images":{"fallback":{"src":"/static/bd2eecf83bf5392a4ac7061919a52914/cd63e/cdtdata.png","srcSet":"/static/bd2eecf83bf5392a4ac7061919a52914/08744/cdtdata.png 145w,\n/static/bd2eecf83bf5392a4ac7061919a52914/3c29b/cdtdata.png 290w,\n/static/bd2eecf83bf5392a4ac7061919a52914/cd63e/cdtdata.png 579w","sizes":"(min-width: 579px) 579px, 100vw"},"sources":[{"srcSet":"/static/bd2eecf83bf5392a4ac7061919a52914/72079/cdtdata.webp 145w,\n/static/bd2eecf83bf5392a4ac7061919a52914/a7f7a/cdtdata.webp 290w,\n/static/bd2eecf83bf5392a4ac7061919a52914/ba6fb/cdtdata.webp 579w","type":"image/webp","sizes":"(min-width: 579px) 579px, 100vw"}]},"width":579,"height":579}}},"title":"Centre for Doctoral Training (CDT) in Data Centric Engineering","author":"Prof Eram Rizvi (PI), Prof Mark Sandler (CI), Prof Nick Bryan-Kinns (CI)","date":null},"html":"","id":"e68ade9f-702f-5695-9a7d-e2ab94af8c72"},{"fields":{"slug":"/projects/aimcdt"},"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/98704461ac8eeac7d8b8a64dc1520bf4/7a590/aimcdt.png","srcSet":"/static/98704461ac8eeac7d8b8a64dc1520bf4/4b686/aimcdt.png 154w,\n/static/98704461ac8eeac7d8b8a64dc1520bf4/d2213/aimcdt.png 308w,\n/static/98704461ac8eeac7d8b8a64dc1520bf4/7a590/aimcdt.png 615w","sizes":"(min-width: 615px) 615px, 100vw"},"sources":[{"srcSet":"/static/98704461ac8eeac7d8b8a64dc1520bf4/b2942/aimcdt.webp 154w,\n/static/98704461ac8eeac7d8b8a64dc1520bf4/46581/aimcdt.webp 308w,\n/static/98704461ac8eeac7d8b8a64dc1520bf4/fa942/aimcdt.webp 615w","type":"image/webp","sizes":"(min-width: 615px) 615px, 100vw"}]},"width":615,"height":615}}},"title":"UKRI Centre for Doctoral Training in Artificial Intelligence and Music (AIM)","author":"Prof Simon Dixon (PI), Dr Mathieu Barthet (CI), Dr Nick Bryan-Kinns (CI), Dr Gyorgy Fazekas (CI), Prof Mark Sandler (CI), Dr Andrew McPherson (CI), Dr Emmanouil Benetos (CI)","date":null},"html":"","id":"237af1c8-14dc-5167-a5e1-fa55e6860dea"},{"fields":{"slug":"/projects/rudiments"},"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#181808","images":{"fallback":{"src":"/static/cce6762544faa60a4db655637da72c49/5c8f1/rudiments.jpg","srcSet":"/static/cce6762544faa60a4db655637da72c49/be5ed/rudiments.jpg 500w,\n/static/cce6762544faa60a4db655637da72c49/5a7c3/rudiments.jpg 1000w,\n/static/cce6762544faa60a4db655637da72c49/5c8f1/rudiments.jpg 2000w","sizes":"(min-width: 2000px) 2000px, 100vw"},"sources":[{"srcSet":"/static/cce6762544faa60a4db655637da72c49/5f169/rudiments.webp 500w,\n/static/cce6762544faa60a4db655637da72c49/3cd29/rudiments.webp 1000w,\n/static/cce6762544faa60a4db655637da72c49/62c39/rudiments.webp 2000w","type":"image/webp","sizes":"(min-width: 2000px) 2000px, 100vw"}]},"width":2000,"height":2000}}},"title":"RUDIMENTS: Reflective Understanding of Digital Instruments as Musical Entanglements","author":"Prof Andrew McPherson","date":null},"html":"","id":"0414c861-e324-50b1-a8ff-2850a2fca4d6"},{"fields":{"slug":"/projects/bela"},"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/ab849585d66cbe4457ad55b0fdc5e451/0a45a/bela.jpg","srcSet":"/static/ab849585d66cbe4457ad55b0fdc5e451/1a361/bela.jpg 225w,\n/static/ab849585d66cbe4457ad55b0fdc5e451/cd18a/bela.jpg 450w,\n/static/ab849585d66cbe4457ad55b0fdc5e451/0a45a/bela.jpg 900w","sizes":"(min-width: 900px) 900px, 100vw"},"sources":[{"srcSet":"/static/ab849585d66cbe4457ad55b0fdc5e451/252a0/bela.webp 225w,\n/static/ab849585d66cbe4457ad55b0fdc5e451/2890f/bela.webp 450w,\n/static/ab849585d66cbe4457ad55b0fdc5e451/3987a/bela.webp 900w","type":"image/webp","sizes":"(min-width: 900px) 900px, 100vw"}]},"width":900,"height":900}}},"title":"Bela / Royal Academy of Engineering Senior Research Fellow in Embedded Music Computing","author":"Prof Andrew McPherson (PI)","date":null},"html":"","id":"b49fde0c-1a42-5815-8c73-117d498a7400"},{"fields":{"slug":"/projects/elderwellbeing"},"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/6798bd0a21b481f294603af17e6e5c13/9b57b/elderwellbeing.png","srcSet":"/static/6798bd0a21b481f294603af17e6e5c13/22dd1/elderwellbeing.png 102w,\n/static/6798bd0a21b481f294603af17e6e5c13/5b15c/elderwellbeing.png 205w,\n/static/6798bd0a21b481f294603af17e6e5c13/9b57b/elderwellbeing.png 409w","sizes":"(min-width: 409px) 409px, 100vw"},"sources":[{"srcSet":"/static/6798bd0a21b481f294603af17e6e5c13/9b4d3/elderwellbeing.webp 102w,\n/static/6798bd0a21b481f294603af17e6e5c13/24bbe/elderwellbeing.webp 205w,\n/static/6798bd0a21b481f294603af17e6e5c13/d1608/elderwellbeing.webp 409w","type":"image/webp","sizes":"(min-width: 409px) 409px, 100vw"}]},"width":409,"height":409}}},"title":"Designing new musical technologies for older adults' wellbeing","author":"Dr Jennifer MacRitchie (PI, Sheffield), Prof Andrew McPherson (CI), and 2 others","date":null},"html":"","id":"c701f3d3-aeb3-55ff-8b41-f0e044fa5c2d"},{"fields":{"slug":"/projects/steinbergaim"},"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#4848a8","images":{"fallback":{"src":"/static/667dfeac59460a16f71a264dfc9745d7/6c0ff/rudiments.png","srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/de3a1/rudiments.png 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/30cdc/rudiments.png 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/6c0ff/rudiments.png 599w","sizes":"(min-width: 599px) 599px, 100vw"},"sources":[{"srcSet":"/static/667dfeac59460a16f71a264dfc9745d7/c65bc/rudiments.webp 150w,\n/static/667dfeac59460a16f71a264dfc9745d7/078c3/rudiments.webp 300w,\n/static/667dfeac59460a16f71a264dfc9745d7/3b6e5/rudiments.webp 599w","type":"image/webp","sizes":"(min-width: 599px) 599px, 100vw"}]},"width":599,"height":599}}},"title":"Smart Channel Strip using Neural Audio Processing","author":"Dr George Fazekas (PI)","date":null},"html":"","id":"7c543bb2-3b4e-5d04-9f40-ff872301abb2"}]},"news":{"nodes":[{"fields":{"slug":"/news/2023-05-26.C4DM-at_ICMPC_2023"},"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/2b6f0fee66cf2e8e3786de08167a40f2/ca426/ICMPC2023.png","srcSet":"/static/2b6f0fee66cf2e8e3786de08167a40f2/bb5d0/ICMPC2023.png 126w,\n/static/2b6f0fee66cf2e8e3786de08167a40f2/2cc56/ICMPC2023.png 253w,\n/static/2b6f0fee66cf2e8e3786de08167a40f2/ca426/ICMPC2023.png 505w","sizes":"(min-width: 505px) 505px, 100vw"},"sources":[{"srcSet":"/static/2b6f0fee66cf2e8e3786de08167a40f2/fabbe/ICMPC2023.webp 126w,\n/static/2b6f0fee66cf2e8e3786de08167a40f2/2d900/ICMPC2023.webp 253w,\n/static/2b6f0fee66cf2e8e3786de08167a40f2/0b3af/ICMPC2023.webp 505w","type":"image/webp","sizes":"(min-width: 505px) 505px, 100vw"}]},"width":505,"height":505}}},"title":"C4DM at ICMPC 2023","author":"Admin","date":"Fri 26 May 2023"},"html":"<p>From 24 to 28 August, several C4DM researchers will participate in the <b><a href=\"https://jsmpc.org/ICMPC17/\">17th International Conference on Music Perception and Cognition (ICMPC 2023)</a></b>.</p>\n<p>Below is a list of all the contributions authored or co-authored by C4DM members:</p>\n<ul>\n<li>\n<p><strong>Analysing the Gendering of Music in Toy Commercials via Mid-level Perceptual Features</strong> by Luca Marinelli, and Charalampos Saitis</p>\n</li>\n<li>\n<p><strong>Exploring the Role of Audio and Lyrics in Explaining Moral Worldviews</strong> by Vjosa Preniqi, Kyriaki Kalimeri, and Charalampos Saitis</p>\n</li>\n<li>\n<p><strong>Evolution of Moral Valence in Lyrics Over Time</strong> by Vjosa Preniqi, Kyriaki Kalimeri, Andreas Kaltenbrunner, and Charalampos Saitis</p>\n</li>\n<li>\n<p><strong>Modelling the perception of large-scale order in music</strong> by Edward Hall and Marcus Pearce</p>\n</li>\n<li>\n<p><strong>The Billboard Melodic Music Dataset and Trajectories in Western Pop Music</strong> by Madeline Hamilton and Marcus Pearce</p>\n</li>\n<li>\n<p><strong>Informational constraints and trade-offs in melodies across cultures</strong> by John McBride, Marcus Pearce and Tsvi Tlusty</p>\n</li>\n<li>\n<p><strong>The Cultural Distance Hypothesis and its Impact on Melodic Perception</strong> by Mathias Klarlund, Elvira Brattico, Yi Du, Marcus Pearce, Peter Vuust, Morten Overgaard and Yiyang Wu</p>\n</li>\n<li>\n<p><strong>Predictive processes shape the relation between groove and syncopation</strong> by Tomas Matthews, Jonathan Cannon, Victor Pando-Naude, Jan Stupacher, Isaac Romkey, Thomas Kaplan, Gunvor Bertelsen, Alexandre Celma Miralles, Virginia Penhune and Peter Vuust</p>\n</li>\n</ul>\n<p>The following symposia are co-organised by C4DM members:</p>\n<ul>\n<li>\n<p><strong>Symposium: Predictions in Music: Neurocognitive Insights and Computational Approaches</strong> by Vincent Cheung, Peter Harrison, Psyche Loui, Marcus Pearce and Daniela Sammler</p>\n</li>\n<li>\n<p><strong>Symposium: Modelling rhythm perception beyond the beat</strong> by Atser Damsma, Fleur Bouwer, Lauren Fink, Jonathan Cannon, Keith Doelling, Jessica Grahn, Henkjan Honing and Thomas Kaplan</p>\n</li>\n</ul>\n<p>Happy ICMPCing!</p>","id":"a0eca885-ec21-52d4-bb86-4ee40d56ae4f"},{"fields":{"slug":"/news/2023-05-26.C4DM-at_NIME_2023"},"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#080808","images":{"fallback":{"src":"/static/4eb8fc854adc4eb2ac813efcfae5b7ef/6c0ff/nime2023.png","srcSet":"/static/4eb8fc854adc4eb2ac813efcfae5b7ef/de3a1/nime2023.png 150w,\n/static/4eb8fc854adc4eb2ac813efcfae5b7ef/30cdc/nime2023.png 300w,\n/static/4eb8fc854adc4eb2ac813efcfae5b7ef/6c0ff/nime2023.png 599w","sizes":"(min-width: 599px) 599px, 100vw"},"sources":[{"srcSet":"/static/4eb8fc854adc4eb2ac813efcfae5b7ef/c65bc/nime2023.webp 150w,\n/static/4eb8fc854adc4eb2ac813efcfae5b7ef/078c3/nime2023.webp 300w,\n/static/4eb8fc854adc4eb2ac813efcfae5b7ef/3b6e5/nime2023.webp 599w","type":"image/webp","sizes":"(min-width: 599px) 599px, 100vw"}]},"width":599,"height":599}}},"title":"C4DM at NIME 2023","author":"Admin","date":"Fri 26 May 2023"},"html":"<p>From 31 May to 3 June, several C4DM researchers will participate in the <b><a href=\"http://nime2023.org/\">2023 International Conference on New Interfaces for Musical Expression (NIME 2023)</a></b>. Once again, this year's edition will have <b><a href=\"https://bela.io/\">Bela</a></b> as an official sponsor.</p>\n<p>Below is a list of all the publications authored or co-authored by C4DM members:</p>\n<ul>\n<li>\n<p><a href=\"\">Instructions not included: Dementia Friendly approaches to DMI Design</a> by Jon Pigrem, Jennifer Macritchie, and Andrew McPherson</p>\n</li>\n<li>\n<p><a href=\"https://sebastianlobbers.com/static/9324af8a968715544e88586037601b98/SketchSynth_Lobbers_NIME.pdf\">SketchSynth: a browser-based sketching interface for sound control</a> by Sebastian Löbbers and György Fazekas</p>\n</li>\n<li>\n<p><a href=\"https://arxiv.org/abs/2305.14867\">Interactive Neural Resonators</a> by Rodrigo Diaz, Charalampos Saitis, and Mark Sandler</p>\n</li>\n<li>\n<p><a href=\"https://teodannemann.files.wordpress.com/2023/05/nime2023_disability-2.pdf\">Music jamming as a participatory design method. A case study with disabled musicians</a> by Teodoro Dannemann</p>\n</li>\n<li>\n<p><a href=\"https://teodannemann.files.wordpress.com/2023/05/nime2023_wip-5.pdf\">The Sabotaging Piano: key-to-pitch remapping as a source of new techniques in piano improvisation</a> by Teodoro Dannemann and Nick Bryan-Kinns</p>\n</li>\n<li>\n<p><a href=\"https://teodannemann.files.wordpress.com/2023/05/nime2023_final-4.pdf\">Self-Sabotage Workshop: a starting point to unravel sabotaging of instruments as a design practice</a> by Teodoro Dannemann, Nick Bryan-Kinns, Andrew McPherson</p>\n</li>\n<li>\n<p><a href=\"https://teodannemann.files.wordpress.com/2023/05/nime2023_music-1.pdf\">Sabotaging Piano Concert (Music Submission)</a> by Teodoro Dannemann</p>\n</li>\n<li>\n<p><a href=\"\">Exploring the (un)ambiguous guitar: A Qualitative Study on the use of Gesture Disambiguation in Augmented Instrument Design</a> by Adan L. Benito Temprano, Teodoro Dannemann, and Andrew P. McPherson</p>\n</li>\n<li>\n<p><a href=\"https://www.teresapelinski.com/documents/2023-nime-cr-pipeline-nn-bela-v3.pdf\">Pipeline for recording datasets and running neural networks on the Bela embedded hardware platform</a> by Teresa Pelinski, Rodrigo Diaz,  Adan L. Benito Temprano, Andrew McPherson</p>\n</li>\n</ul>\n<p>The following workshop is co-organised by C4DM members:</p>\n<ul>\n<li><a href=\"https://qe4nime.github.io/\">Querying Experience with Musical Interaction Workshop</a> by Courtney N. Reed, Eevee Zayas-Garin, and Andrew McPherson</li>\n</ul>\n<p>Happy NIMEing!</p>","id":"458b680f-64c2-5d74-8883-41b17772c24b"},{"fields":{"slug":"/news/2022-09-22.C4DM-students_join_the_Turing"},"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/b14595a1cf9cbbf96f00ff2d37df1499/621f0/turing.png","srcSet":"/static/b14595a1cf9cbbf96f00ff2d37df1499/37ed9/turing.png 121w,\n/static/b14595a1cf9cbbf96f00ff2d37df1499/a3c30/turing.png 242w,\n/static/b14595a1cf9cbbf96f00ff2d37df1499/621f0/turing.png 484w","sizes":"(min-width: 484px) 484px, 100vw"},"sources":[{"srcSet":"/static/b14595a1cf9cbbf96f00ff2d37df1499/368a5/turing.webp 121w,\n/static/b14595a1cf9cbbf96f00ff2d37df1499/ed101/turing.webp 242w,\n/static/b14595a1cf9cbbf96f00ff2d37df1499/6e7b2/turing.webp 484w","type":"image/webp","sizes":"(min-width: 484px) 484px, 100vw"}]},"width":484,"height":484}}},"title":"C4DM students to join the Alan Turing Institute in 2022/23","author":"Admin","date":"Wed 15 Feb 2023"},"html":"<p>Two C4DM PhD students have been given <a href=\"https://www.turing.ac.uk/work-turing/studentships/enrichment\">enrichment awards</a> by the <a href=\"https://www.turing.ac.uk/\">Alan Turing Institute</a>, the UK’s national institute in artificial intelligence and data science, enabling them to join and interact with institute researchers and its community in the 2022/23 academic year.</p>\n<p>Specifically, C4DM PhD student <a href=\"http://eecs.qmul.ac.uk/profiles/banarberker.html\">Berker Banar</a> has been offered a Turing Enrichment Community Award for the project “Towards Composing Contemporary Classical Music using Generative Deep Learning” and C4DM PhD student <a href=\"http://eecs.qmul.ac.uk/profiles/huangjiawen-1.html\">Jiawen Huang</a> has been offered an Enrichment Placement Award for the project “Real-Time Audio-to-Lyrics Alignment for Polyphonic Music”.</p>\n<p>Congratulations to both! For the full story on enrichment awards for Queen Mary doctoral students please read the <a href=\"https://www.qmul.ac.uk/media/news/2022/pr/queen-mary-students-to-gain-valuable-research-experience-through-placements-at-the-alan-turing-institute-.html\">QMUL newsitem</a>.</p>\n<p><i>(22 September 2022)</i></p>","id":"f8575e94-ef6e-5f1a-84cf-51750ffe256a"},{"fields":{"slug":"/news/2022-10-11.C4DM-Seminar_-_Vipul_Arora_-_Model_Adaptation_for_Learning_from_Small_Data"},"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#e8e8e8","images":{"fallback":{"src":"/static/6028f1c51e904116cff0165dba062e8d/b988d/vipulaurora.jpg","srcSet":"/static/6028f1c51e904116cff0165dba062e8d/f18e1/vipulaurora.jpg 96w,\n/static/6028f1c51e904116cff0165dba062e8d/0caa4/vipulaurora.jpg 193w,\n/static/6028f1c51e904116cff0165dba062e8d/b988d/vipulaurora.jpg 385w","sizes":"(min-width: 385px) 385px, 100vw"},"sources":[{"srcSet":"/static/6028f1c51e904116cff0165dba062e8d/8ef24/vipulaurora.webp 96w,\n/static/6028f1c51e904116cff0165dba062e8d/6a483/vipulaurora.webp 193w,\n/static/6028f1c51e904116cff0165dba062e8d/daff6/vipulaurora.webp 385w","type":"image/webp","sizes":"(min-width: 385px) 385px, 100vw"}]},"width":385,"height":385}}},"title":"C4DM Seminar: Dr. Vipul Arora","author":"Jan Novak","date":"Wed 15 Feb 2023"},"html":"<h3>C4DM Seminar: Dr. Vipul Arora</h3>\n<hr>\n<h4>QMUL, School of Electronic Engineering and Computer Science</h4>\n<h4>Centre for Digital Music Seminar Series</h4>\n<p><strong>Seminar by:</strong><br>\nVipul Arora</p>\n<p><strong>Date/time: Wednesday 11th of October, 14:00-15:00</strong></p>\n<p><strong>Location: Hybrid</strong></p>\n<p>Bancroft Road Teaching Room 4.01 in the Mile End campus, or join <a href=\"https://qmul-ac-uk.zoom.us/j/84254407411?pwd=azU2WU1ZWTIvN0pEb3lQZVg2SVNNQT09\">zoom meeting</a>.</p>\n<p>Open to students, staff, alumni, public; all welcome.\nAdmission is FREE, no pre-booking required.</p>\n<hr>\n<p><b>Title</b>: Model Adaptation for Learning from Small Data</p>\n<p><b>Bio</b>:\nVipul Arora is an Associate Professor at the Department of Electrical Engineering, IIT Kanpur, India. He received his B.Tech. and PhD degrees in Electrical Engineering from IIT Kanpur. He did a postdoc at Oxford University (UK), where he developed speech recognition systems using linguistic principles. Then he worked at Amazon in Boston (USA), where he worked on audio classification for developing the Alexa home security system. His current research interest is in developing machine learning algorithms for audio and signal processing. He works on model adaptation, uncertainty modelling and generative machine learning. <a href=\"http://home.iitk.ac.in/~vipular/\">http://home.iitk.ac.in/~vipular/</a></p>\n<p><b>Abstract</b>:\nDeep-learning-based models achieve remarkable performances with big labelled data. However, many practical scenarios face a scarcity of labelled data, while there may still be an abundance of unlabelled data. This talk will discuss several methods to learn effectively from small data. These methods mostly fall under the paradigm of model adaptation and include fine-tuning-based transfer learning, meta-learning, and semi-supervised domain adaptation. These methods’ application to music melody estimation and sensor calibration (regression) problems will be demonstrated. Another way to learn from limited data is by using conditional models. This method will be illustrated for generative machine learning applied to XY models in statistical Physics and field theories in Particle physics. Time permitting, there will be a brief presentation on audio retrieval.</p>\n<p><b>Video recording</b>: <a href=\"https://www.youtube.com/watch?v=-_AS8_NNtWw\">https://www.youtube.com/watch?v=-_AS8_NNtWw</a></p>","id":"3014d431-51d3-5057-8d64-bd1756c327c4"},{"fields":{"slug":"/news/2022-10-26.C4DM-at_DCASE_2022"},"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#584828","images":{"fallback":{"src":"/static/0578136d23b2bff7943757288c183371/af44b/dcase2022.png","srcSet":"/static/0578136d23b2bff7943757288c183371/56197/dcase2022.png 108w,\n/static/0578136d23b2bff7943757288c183371/9b7db/dcase2022.png 217w,\n/static/0578136d23b2bff7943757288c183371/af44b/dcase2022.png 433w","sizes":"(min-width: 433px) 433px, 100vw"},"sources":[{"srcSet":"/static/0578136d23b2bff7943757288c183371/e26a9/dcase2022.webp 108w,\n/static/0578136d23b2bff7943757288c183371/87dc3/dcase2022.webp 217w,\n/static/0578136d23b2bff7943757288c183371/198e2/dcase2022.webp 433w","type":"image/webp","sizes":"(min-width: 433px) 433px, 100vw"}]},"width":433,"height":433}}},"title":"C4DM at DCASE 2022","author":"Jan Novak","date":"Wed 15 Feb 2023"},"html":"<p>On 3-4 November, several C4DM researchers will participate at the <b><a href=\"https://dcase.community/workshop2022/\">7th Workshop on Detection and Classification of Acoustic Scenes and Events (DCASE 2022)</a></b>.  The workshop aims to provide a venue for researchers working on computational analysis of sound events and scene analysis to present and discuss their results, and is organised in conjunction with the <a href=\"https://dcase.community/challenge2022/\">DCASE 2022 Challenge</a>.</p>\n<p>As in previous years, the Centre for Digital Music will have a strong presence at the workshop, both in terms of numbers and overall impact. The below papers presented at DCASE 2022 are authored or co-authored by C4DM members:</p>\n<ul>\n<li>\n<p><a href=\"https://qmro.qmul.ac.uk/xmlui/handle/123456789/82125\">Few-shot bioacoustic event detection: enhanced classifiers for prototypical networks</a>, by Ren Li, Jinhua Liang, Huy Phan</p>\n</li>\n<li>\n<p><a href=\"https://qmro.qmul.ac.uk/xmlui/handle/123456789/82109\">Leveraging label hierarchies for few-shot everyday sound recognition</a>, by Jinhua Liang, Huy Phan, Emmanouil Benetos</p>\n</li>\n<li>\n<p><a href=\"https://arxiv.org/abs/2207.07911\">Few-shot bioacoustic event detection at the DCASE 2022 challenge</a>, by Ines Nolasco, Dan Stowell, Vincent Lostanlen, Shubhr Singh, Veronica Morfi, Ari Strandburg-Peshkin, Lisa Gill, Emily Grout, Ester Vidana-Villa, Joe Morford, Michael Emmerson, Frants Jensen, Helen Whitehead, Hanna Pamula, Ivan Kiskin</p>\n</li>\n<li>\n<p><a href=\"https://www.turing.ac.uk/research/publications/explaining-decisions-anomalous-sound-detectors\">Explaining the decisions of anomalous sound detectors</a>, by Kimberly T. Mai, Toby Davies, Lewis D. Griffin, Emmanouil Benetos</p>\n</li>\n</ul>\n<p>On challenge organisation, C4DM PhD students <a href=\"https://scholar.google.com/citations?user=C1jftogAAAAJ\">Inês Nolasco</a> and <a href=\"http://eecs.qmul.ac.uk/profiles/singhshubhr.html\">Shubhr Singh</a>, QMUL research assistant <a href=\"https://www.qmul.ac.uk/sbbs/staff/michael-emmerson.html\">Michael Emmerson</a>, C4DM alumna and research visitor <a href=\"https://scholar.google.com/citations?user=8izRvu4AAAAJ\">Veronica Morfi</a>, and C4DM alumnus <a href=\"http://www.mcld.co.uk/research/\">Dan Stowell</a> are all involved in the organisation of the DCASE 2022 Challenge task on <a href=\"https://dcase.community/challenge2022/task-few-shot-bioacoustic-event-detection\">Few-shot Bioacoustic Event Detection</a>, focusing on sound event detection in a few-shot learning setting for animal (mammal and bird) vocalisations.</p>\n<p>See you all at DCASE!</p>","id":"058db84f-cf26-5e15-9378-807cb6f0e300"},{"fields":{"slug":"/news/2023-05-11.C4DM-Seminar_-_Anja Volk_-_Understanding_and_employing_patterns_in_music"},"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#e8e8c8","images":{"fallback":{"src":"/static/da5db3a8ddd656d9712dbbd89514fbfc/97a19/anjavolk.jpg","srcSet":"/static/da5db3a8ddd656d9712dbbd89514fbfc/73bb6/anjavolk.jpg 120w,\n/static/da5db3a8ddd656d9712dbbd89514fbfc/f9edd/anjavolk.jpg 240w,\n/static/da5db3a8ddd656d9712dbbd89514fbfc/97a19/anjavolk.jpg 480w","sizes":"(min-width: 480px) 480px, 100vw"},"sources":[{"srcSet":"/static/da5db3a8ddd656d9712dbbd89514fbfc/507b0/anjavolk.webp 120w,\n/static/da5db3a8ddd656d9712dbbd89514fbfc/8d565/anjavolk.webp 240w,\n/static/da5db3a8ddd656d9712dbbd89514fbfc/21b1a/anjavolk.webp 480w","type":"image/webp","sizes":"(min-width: 480px) 480px, 100vw"}]},"width":480,"height":480}}},"title":"C4DM Seminar: Anja Volk","author":"Admin","date":"Wed 15 Feb 2023"},"html":"<h3>C4DM Seminar: Anja Volk</h3>\n<hr>\n<h4>QMUL, School of Electronic Engineering and Computer Science</h4>\n<h4>Centre for Digital Music Seminar Series</h4>\n<p><strong>Seminar by:</strong><br>\nAnja Volk</p>\n<p><strong>Date/time:  11th of May, 16:00-17:00</strong></p>\n<p><strong>Location: G2, Mile End Campus</strong></p>\n<p>Open to students, staff, alumni, public; all welcome.\nAdmission is FREE, no pre-booking required.</p>\n<hr>\n<p><b>Title</b>: Clastic Music: From rhythmic latent spaces to a web-based music release</p>\n<p><b>Bio</b>:<br>\nAnja Volk is Professor of Music Information Computing at Utrecht University and has a dual background in mathematics and musicology which she applies to cross-disciplinary approaches to music. Her work has helped bridge the gap between scientific and humanistic approaches while working in interdisciplinary research teams in Germany, the USA and the Netherlands. Anja has co-founded several international initiatives, most notably the International Society for Mathematics and Computation in Music (SMCM), the flagship journal of the International Society for Music Information Retrieval (TISMIR), and the Women in MIR (WIMIR) mentoring program, which organizes yearly mentoring rounds with participants from academia and industry, in order to foster greater diversity in MIR. She is also committed to connecting different research communities and providing interdisciplinary education for the next generation through the organization of international workshops, such as the Lorentz Center in Leiden workshops on music similarity (2015), computational ethnomusicology (2017) and music, computing, and health (2019).</p>\n<p><b>Abstract</b>:\nIn this talk, I present research of the Music Information Computing group at Utrecht University on investigating musical patterns with computational means to enhance our understanding of music, and to employ these patterns within different interaction contexts. Starting with computational music analysis dedicated to pattern discovery, I will discuss then the bridge to employing patterns for training in education and health, such as in music-based games for visually impaired children, musical attention control training, and collaborative games for the rhythmic training of children with autism.</p>","id":"15d44cd7-4a50-5e7d-a160-2d1baf40c7bf"}]}}}