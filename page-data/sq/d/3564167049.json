{"data":{"projects":{"nodes":[{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#080838","images":{"fallback":{"src":"/c4dm-website/static/bd2eecf83bf5392a4ac7061919a52914/cd63e/cdtdata.png","srcSet":"/c4dm-website/static/bd2eecf83bf5392a4ac7061919a52914/08744/cdtdata.png 145w,\n/c4dm-website/static/bd2eecf83bf5392a4ac7061919a52914/3c29b/cdtdata.png 290w,\n/c4dm-website/static/bd2eecf83bf5392a4ac7061919a52914/cd63e/cdtdata.png 579w","sizes":"(min-width: 579px) 579px, 100vw"},"sources":[{"srcSet":"/c4dm-website/static/bd2eecf83bf5392a4ac7061919a52914/72079/cdtdata.webp 145w,\n/c4dm-website/static/bd2eecf83bf5392a4ac7061919a52914/a7f7a/cdtdata.webp 290w,\n/c4dm-website/static/bd2eecf83bf5392a4ac7061919a52914/ba6fb/cdtdata.webp 579w","type":"image/webp","sizes":"(min-width: 579px) 579px, 100vw"}]},"width":579,"height":579}}},"status":"active","tags":["academic"],"title":"Centre for Doctoral Training (CDT) in Data Centric Engineering","author":"Prof Eram Rizvi (PI), Prof Mark Sandler (CI), Prof Nick Bryan-Kinns (CI)","begin":"2020","end":"2028","grant":"EPSRC Training Grant EP/V519935/1","amount":"£1,629,373","link":"https://gtr.ukri.org/projects?ref=EP%2FV519935%2F1"},"id":"e68ade9f-702f-5695-9a7d-e2ab94af8c72"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/c4dm-website/static/98704461ac8eeac7d8b8a64dc1520bf4/7a590/aimcdt.png","srcSet":"/c4dm-website/static/98704461ac8eeac7d8b8a64dc1520bf4/4b686/aimcdt.png 154w,\n/c4dm-website/static/98704461ac8eeac7d8b8a64dc1520bf4/d2213/aimcdt.png 308w,\n/c4dm-website/static/98704461ac8eeac7d8b8a64dc1520bf4/7a590/aimcdt.png 615w","sizes":"(min-width: 615px) 615px, 100vw"},"sources":[{"srcSet":"/c4dm-website/static/98704461ac8eeac7d8b8a64dc1520bf4/b2942/aimcdt.webp 154w,\n/c4dm-website/static/98704461ac8eeac7d8b8a64dc1520bf4/46581/aimcdt.webp 308w,\n/c4dm-website/static/98704461ac8eeac7d8b8a64dc1520bf4/fa942/aimcdt.webp 615w","type":"image/webp","sizes":"(min-width: 615px) 615px, 100vw"}]},"width":615,"height":615}}},"status":"active","tags":null,"title":"UKRI Centre for Doctoral Training in Artificial Intelligence and Music (AIM)","author":"Prof Simon Dixon (PI), Dr Mathieu Barthet (CI), Dr Nick Bryan-Kinns (CI), Dr Gyorgy Fazekas (CI), Prof Mark Sandler (CI), Dr Andrew McPherson (CI), Dr Emmanouil Benetos (CI)","begin":"2019","end":"2027","grant":"EPSRC Grant EP/S022694/1","amount":"£6,240,207","link":"https://www.aim.qmul.ac.uk/"},"id":"237af1c8-14dc-5167-a5e1-fa55e6860dea"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#181808","images":{"fallback":{"src":"/c4dm-website/static/cce6762544faa60a4db655637da72c49/f19bc/rudiments.jpg","srcSet":"/c4dm-website/static/cce6762544faa60a4db655637da72c49/26cfb/rudiments.jpg 500w,\n/c4dm-website/static/cce6762544faa60a4db655637da72c49/1b035/rudiments.jpg 1000w,\n/c4dm-website/static/cce6762544faa60a4db655637da72c49/f19bc/rudiments.jpg 2000w","sizes":"(min-width: 2000px) 2000px, 100vw"},"sources":[{"srcSet":"/c4dm-website/static/cce6762544faa60a4db655637da72c49/921bf/rudiments.webp 500w,\n/c4dm-website/static/cce6762544faa60a4db655637da72c49/b7ef5/rudiments.webp 1000w,\n/c4dm-website/static/cce6762544faa60a4db655637da72c49/c9c6a/rudiments.webp 2000w","type":"image/webp","sizes":"(min-width: 2000px) 2000px, 100vw"}]},"width":2000,"height":1333}}},"status":"active","tags":["academic"],"title":"RUDIMENTS: Reflective Understanding of Digital Instruments as Musical Entanglements","author":"Prof Andrew McPherson","begin":"2022","end":"2027","grant":"ERC Consolidator Grant / UKRI Research Grant EP/X023478/1","amount":"£1,723,185","link":"https://gtr.ukri.org/projects?ref=EP%2FX023478%2F1"},"id":"0414c861-e324-50b1-a8ff-2850a2fca4d6"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/c4dm-website/static/ab849585d66cbe4457ad55b0fdc5e451/0a45a/bela.jpg","srcSet":"/c4dm-website/static/ab849585d66cbe4457ad55b0fdc5e451/1a361/bela.jpg 225w,\n/c4dm-website/static/ab849585d66cbe4457ad55b0fdc5e451/cd18a/bela.jpg 450w,\n/c4dm-website/static/ab849585d66cbe4457ad55b0fdc5e451/0a45a/bela.jpg 900w","sizes":"(min-width: 900px) 900px, 100vw"},"sources":[{"srcSet":"/c4dm-website/static/ab849585d66cbe4457ad55b0fdc5e451/252a0/bela.webp 225w,\n/c4dm-website/static/ab849585d66cbe4457ad55b0fdc5e451/2890f/bela.webp 450w,\n/c4dm-website/static/ab849585d66cbe4457ad55b0fdc5e451/3987a/bela.webp 900w","type":"image/webp","sizes":"(min-width: 900px) 900px, 100vw"}]},"width":900,"height":900}}},"status":"active","tags":["industry"],"title":"Bela / Royal Academy of Engineering Senior Research Fellow in Embedded Music Computing","author":"Prof Andrew McPherson (PI)","begin":"2021","end":"2026","grant":"RAEng Senior Research Fellowship","amount":"£208,776","link":"https://www.raeng.org.uk/grants-prizes/grants/support-for-research/research-chairs/current-and-recent-awards"},"id":"b49fde0c-1a42-5815-8c73-117d498a7400"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/c4dm-website/static/6798bd0a21b481f294603af17e6e5c13/ebb6b/elderwellbeing.png","srcSet":"/c4dm-website/static/6798bd0a21b481f294603af17e6e5c13/5293c/elderwellbeing.png 102w,\n/c4dm-website/static/6798bd0a21b481f294603af17e6e5c13/12126/elderwellbeing.png 205w,\n/c4dm-website/static/6798bd0a21b481f294603af17e6e5c13/ebb6b/elderwellbeing.png 409w","sizes":"(min-width: 409px) 409px, 100vw"},"sources":[{"srcSet":"/c4dm-website/static/6798bd0a21b481f294603af17e6e5c13/cc485/elderwellbeing.webp 102w,\n/c4dm-website/static/6798bd0a21b481f294603af17e6e5c13/be984/elderwellbeing.webp 205w,\n/c4dm-website/static/6798bd0a21b481f294603af17e6e5c13/03dd7/elderwellbeing.webp 409w","type":"image/webp","sizes":"(min-width: 409px) 409px, 100vw"}]},"width":409,"height":406}}},"status":"active","tags":null,"title":"Designing new musical technologies for older adults' wellbeing","author":"Dr Jennifer MacRitchie (PI, Sheffield), Prof Andrew McPherson (CI), and 2 others","begin":"2021","end":"2025","grant":"UKRI Future Leaders Fellowship","amount":"£946,672 (total), £24,879 (QMUL)","link":"https://gtr.ukri.org/projects?ref=MR%2FT040580%2F1"},"id":"c701f3d3-aeb3-55ff-8b41-f0e044fa5c2d"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#4848a8","images":{"fallback":{"src":"/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/47fd0/rudiments.png","srcSet":"/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/265e7/rudiments.png 150w,\n/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/eb6c9/rudiments.png 300w,\n/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/47fd0/rudiments.png 599w","sizes":"(min-width: 599px) 599px, 100vw"},"sources":[{"srcSet":"/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/7a0a5/rudiments.webp 150w,\n/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/bdee7/rudiments.webp 300w,\n/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/214c6/rudiments.webp 599w","type":"image/webp","sizes":"(min-width: 599px) 599px, 100vw"}]},"width":599,"height":545}}},"status":"active","tags":null,"title":"Smart Channel Strip using Neural Audio Processing","author":"Dr George Fazekas (PI)","begin":"2021","end":"2025","grant":"AIM CDT PhD studentship","amount":"£109,649","link":"https://www.aim.qmul.ac.uk/"},"id":"7c543bb2-3b4e-5d04-9f40-ff872301abb2"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#080808","images":{"fallback":{"src":"/c4dm-website/static/c993712101c8512ecb7672308c273663/b8d58/bridgingthegap.png","srcSet":"/c4dm-website/static/c993712101c8512ecb7672308c273663/3c983/bridgingthegap.png 384w,\n/c4dm-website/static/c993712101c8512ecb7672308c273663/ad503/bridgingthegap.png 768w,\n/c4dm-website/static/c993712101c8512ecb7672308c273663/b8d58/bridgingthegap.png 1536w","sizes":"(min-width: 1536px) 1536px, 100vw"},"sources":[{"srcSet":"/c4dm-website/static/c993712101c8512ecb7672308c273663/c0efa/bridgingthegap.webp 384w,\n/c4dm-website/static/c993712101c8512ecb7672308c273663/a9cbf/bridgingthegap.webp 768w,\n/c4dm-website/static/c993712101c8512ecb7672308c273663/0300a/bridgingthegap.webp 1536w","type":"image/webp","sizes":"(min-width: 1536px) 1536px, 100vw"}]},"width":1536,"height":1079}}},"status":"active","tags":["academic"],"title":"Bridging the Gap - visually impaired and sighted music producers working side by side","author":"Prof Franziska Schroeder (PI, QUB), Prof Andrew McPherson (CI, QMUL)","begin":"2021","end":"2024","grant":"AHRC Grant AH/V011340/1","amount":"£576,879","link":"https://gtr.ukri.org/projects?ref=AH%2FV011340%2F1"},"id":"df4c77a3-f868-5e3c-aefb-6767162fc318"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f87838","images":{"fallback":{"src":"/c4dm-website/static/d6b5df0c36ed85881d1237b2030f4625/c868e/dame.png","srcSet":"/c4dm-website/static/d6b5df0c36ed85881d1237b2030f4625/c9352/dame.png 98w,\n/c4dm-website/static/d6b5df0c36ed85881d1237b2030f4625/546fa/dame.png 196w,\n/c4dm-website/static/d6b5df0c36ed85881d1237b2030f4625/c868e/dame.png 392w","sizes":"(min-width: 392px) 392px, 100vw"},"sources":[{"srcSet":"/c4dm-website/static/d6b5df0c36ed85881d1237b2030f4625/f1ce5/dame.webp 98w,\n/c4dm-website/static/d6b5df0c36ed85881d1237b2030f4625/cace6/dame.webp 196w,\n/c4dm-website/static/d6b5df0c36ed85881d1237b2030f4625/7bd5a/dame.webp 392w","type":"image/webp","sizes":"(min-width: 392px) 392px, 100vw"}]},"width":392,"height":392}}},"status":"active","tags":null,"title":"Centre for Doctoral Training in Data-informed Audience-centric Media Engineering (DAME)","author":"Prof Mark Sandler (PI), Prof Andrea Cavallaro (CI), Prof Pat Healy (CI), Dr Gareth Tyson (CI), and Dr Charalampos Saitis (CI)","begin":"2021","end":"2024","grant":null,"amount":"£177,000 (standard stipend) + £27,000 (contribution from BBC)","link":"https://dame.qmul.ac.uk/"},"id":"e4433bb8-943f-519a-bc83-e592c3199df5"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/c4dm-website/static/6711458031491075c5c84e437de90c34/2fc4b/graphnex.png","srcSet":"/c4dm-website/static/6711458031491075c5c84e437de90c34/cb66a/graphnex.png 95w,\n/c4dm-website/static/6711458031491075c5c84e437de90c34/930a2/graphnex.png 190w,\n/c4dm-website/static/6711458031491075c5c84e437de90c34/2fc4b/graphnex.png 380w","sizes":"(min-width: 380px) 380px, 100vw"},"sources":[{"srcSet":"/c4dm-website/static/6711458031491075c5c84e437de90c34/fded6/graphnex.webp 95w,\n/c4dm-website/static/6711458031491075c5c84e437de90c34/b5e25/graphnex.webp 190w,\n/c4dm-website/static/6711458031491075c5c84e437de90c34/b8a7e/graphnex.webp 380w","type":"image/webp","sizes":"(min-width: 380px) 380px, 100vw"}]},"width":380,"height":217}}},"status":"active","tags":null,"title":"GraphNEx: Graph Neural Networks for Explainable Artificial Intelligence","author":"Prof Andrea Cavallaro (QMUL PI), Dr Emmanouil Benetos (CI)","begin":"2021","end":"2024","grant":"CHIST-ERA / EPSRC grant EP/V062107/1","amount":"£293,434","link":"https://gtr.ukri.org/projects?ref=EP%2FV062107%2F1"},"id":"de18f20d-6c10-52d0-a7b0-4a8c9c7f8699"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#4848a8","images":{"fallback":{"src":"/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/47fd0/rudiments.png","srcSet":"/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/265e7/rudiments.png 150w,\n/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/eb6c9/rudiments.png 300w,\n/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/47fd0/rudiments.png 599w","sizes":"(min-width: 599px) 599px, 100vw"},"sources":[{"srcSet":"/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/7a0a5/rudiments.webp 150w,\n/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/bdee7/rudiments.webp 300w,\n/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/214c6/rudiments.webp 599w","type":"image/webp","sizes":"(min-width: 599px) 599px, 100vw"}]},"width":599,"height":545}}},"status":"active","tags":["academic"],"title":"Music and Disability: Deconstructing the barriers to full participation","author":"Dr Victoria Kinsella (PI, BCU), Prof Andrew McPherson (CI, QMUL)","begin":"2022","end":"2024","grant":"AHRC Grant AH/W010429/1","amount":"£29,812","link":"https://gtr.ukri.org/projects?ref=AH%2FW010429%2F1"},"id":"666f606f-be82-5c0a-81cc-c7661df3c2ac"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#4848a8","images":{"fallback":{"src":"/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/47fd0/rudiments.png","srcSet":"/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/265e7/rudiments.png 150w,\n/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/eb6c9/rudiments.png 300w,\n/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/47fd0/rudiments.png 599w","sizes":"(min-width: 599px) 599px, 100vw"},"sources":[{"srcSet":"/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/7a0a5/rudiments.webp 150w,\n/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/bdee7/rudiments.webp 300w,\n/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/214c6/rudiments.webp 599w","type":"image/webp","sizes":"(min-width: 599px) 599px, 100vw"}]},"width":599,"height":545}}},"status":"active","tags":null,"title":"Industry-scale machine listening for music and audio data","author":"Prof Simon Dixon (PI)","begin":"2020","end":"2024","grant":"AIM CDT PhD studentship","amount":"£108,000","link":"https://www.aim.qmul.ac.uk/"},"id":"15b1b13f-30ef-5a0b-bdcb-d2fb48dafefc"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#4848a8","images":{"fallback":{"src":"/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/47fd0/rudiments.png","srcSet":"/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/265e7/rudiments.png 150w,\n/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/eb6c9/rudiments.png 300w,\n/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/47fd0/rudiments.png 599w","sizes":"(min-width: 599px) 599px, 100vw"},"sources":[{"srcSet":"/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/7a0a5/rudiments.webp 150w,\n/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/bdee7/rudiments.webp 300w,\n/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/214c6/rudiments.webp 599w","type":"image/webp","sizes":"(min-width: 599px) 599px, 100vw"}]},"width":599,"height":545}}},"status":"active","tags":null,"title":"Industry-scale machine listening for music and audio data","author":"Prof Simon Dixon (PI)","begin":"2020","end":"2024","grant":"AIM CDT PhD studentship","amount":"£108,000","link":"https://www.aim.qmul.ac.uk/"},"id":"09dfe751-bb66-555e-8350-48997620240b"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#080808","images":{"fallback":{"src":"/c4dm-website/static/96e93ddaa92c9375174d9c309c3bed43/a764f/digitaljazz.jpg","srcSet":"/c4dm-website/static/96e93ddaa92c9375174d9c309c3bed43/fb67e/digitaljazz.jpg 480w,\n/c4dm-website/static/96e93ddaa92c9375174d9c309c3bed43/3059d/digitaljazz.jpg 960w,\n/c4dm-website/static/96e93ddaa92c9375174d9c309c3bed43/a764f/digitaljazz.jpg 1920w","sizes":"(min-width: 1920px) 1920px, 100vw"},"sources":[{"srcSet":"/c4dm-website/static/96e93ddaa92c9375174d9c309c3bed43/3a3a2/digitaljazz.webp 480w,\n/c4dm-website/static/96e93ddaa92c9375174d9c309c3bed43/bde8a/digitaljazz.webp 960w,\n/c4dm-website/static/96e93ddaa92c9375174d9c309c3bed43/c512e/digitaljazz.webp 1920w","type":"image/webp","sizes":"(min-width: 1920px) 1920px, 100vw"}]},"width":1920,"height":1080}}},"status":"active","tags":null,"title":"New Directions in Digital Jazz Studies: Music Information Retrieval and AI Support for Jazz Scholarship in Digital Archives","author":"Dr Tillman Weyde (City, PI), Prof Simon Dixon (CI), plus two others","begin":"2021","end":"2023","grant":"AHRC grant AH/V009699/1","amount":"£50,845 (QMUL), £202,566 (total)","link":"https://gtr.ukri.org/projects?ref=AH%2FV009699%2F1"},"id":"a55ec5e2-464a-560e-9358-5c5d8dc379da"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#4848a8","images":{"fallback":{"src":"/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/47fd0/rudiments.png","srcSet":"/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/265e7/rudiments.png 150w,\n/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/eb6c9/rudiments.png 300w,\n/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/47fd0/rudiments.png 599w","sizes":"(min-width: 599px) 599px, 100vw"},"sources":[{"srcSet":"/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/7a0a5/rudiments.webp 150w,\n/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/bdee7/rudiments.webp 300w,\n/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/214c6/rudiments.webp 599w","type":"image/webp","sizes":"(min-width: 599px) 599px, 100vw"}]},"width":599,"height":545}}},"status":"active","tags":["industry"],"title":"Deep learning technologies for multi-instrument automatic music transcription","author":"Dr Emmanouil Benetos (PI), Prof Simon Dixon (CI)","begin":"2022","end":"2023","grant":"Huawei Technologies Düsseldorf","amount":"£252,000","link":"https://huawei.eu/"},"id":"e3b9fcbc-6097-521f-8d9c-94d239cca557"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#080808","images":{"fallback":{"src":"/c4dm-website/static/4d5f308fe2613c55bb6b0e19394b9fa9/4a49b/jade.jpg","srcSet":"/c4dm-website/static/4d5f308fe2613c55bb6b0e19394b9fa9/b4dad/jade.jpg 320w,\n/c4dm-website/static/4d5f308fe2613c55bb6b0e19394b9fa9/3440d/jade.jpg 640w,\n/c4dm-website/static/4d5f308fe2613c55bb6b0e19394b9fa9/4a49b/jade.jpg 1280w","sizes":"(min-width: 1280px) 1280px, 100vw"},"sources":[{"srcSet":"/c4dm-website/static/4d5f308fe2613c55bb6b0e19394b9fa9/c0bcc/jade.webp 320w,\n/c4dm-website/static/4d5f308fe2613c55bb6b0e19394b9fa9/17574/jade.webp 640w,\n/c4dm-website/static/4d5f308fe2613c55bb6b0e19394b9fa9/71d4d/jade.webp 1280w","type":"image/webp","sizes":"(min-width: 1280px) 1280px, 100vw"}]},"width":1280,"height":720}}},"status":"complete","tags":null,"title":"JADE: Joint Academic Data science Endeavour","author":"Wesley Gavin Armour (PI, Oxford), Prof Mark Sandler (CI, QMUL), plus 24 others","begin":"2020","end":"2023","grant":"EPSRC Grant EP/T022205/1","amount":"£5,539,933","link":"https://gtr.ukri.org/projects?ref=EP%2FT022205%2F1"},"id":"d5e21c61-0716-5927-a348-94bb02b33cf6"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#4848a8","images":{"fallback":{"src":"/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/47fd0/rudiments.png","srcSet":"/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/265e7/rudiments.png 150w,\n/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/eb6c9/rudiments.png 300w,\n/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/47fd0/rudiments.png 599w","sizes":"(min-width: 599px) 599px, 100vw"},"sources":[{"srcSet":"/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/7a0a5/rudiments.webp 150w,\n/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/bdee7/rudiments.webp 300w,\n/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/214c6/rudiments.webp 599w","type":"image/webp","sizes":"(min-width: 599px) 599px, 100vw"}]},"width":599,"height":545}}},"status":"active","tags":null,"title":"Optical music recognition using deep learning","author":"Dr George Fazekas (PI)","begin":"2019","end":"2023","grant":"AIM CDT PhD studentship","amount":"£109,649","link":"https://www.aim.qmul.ac.uk/"},"id":"c49d4daa-387f-5374-8b7b-f258d1a4d7a6"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#4848a8","images":{"fallback":{"src":"/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/47fd0/rudiments.png","srcSet":"/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/265e7/rudiments.png 150w,\n/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/eb6c9/rudiments.png 300w,\n/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/47fd0/rudiments.png 599w","sizes":"(min-width: 599px) 599px, 100vw"},"sources":[{"srcSet":"/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/7a0a5/rudiments.webp 150w,\n/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/bdee7/rudiments.webp 300w,\n/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/214c6/rudiments.webp 599w","type":"image/webp","sizes":"(min-width: 599px) 599px, 100vw"}]},"width":599,"height":545}}},"status":"active","tags":null,"title":"Perceptual end to end learning for music understanding","author":"Dr George Fazekas (PI)","begin":"2019","end":"2023","grant":"AIM CDT PhD studentship","amount":"£27,000 ","link":"https://www.aim.qmul.ac.uk/"},"id":"4544efbd-9cf2-5b05-bfa7-dfee028de7ee"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/c4dm-website/static/6cf2e7126aeb16a6a13f73a77f91491c/a89ca/universalaim.jpg","srcSet":"/c4dm-website/static/6cf2e7126aeb16a6a13f73a77f91491c/96deb/universalaim.jpg 150w,\n/c4dm-website/static/6cf2e7126aeb16a6a13f73a77f91491c/0fdf4/universalaim.jpg 300w,\n/c4dm-website/static/6cf2e7126aeb16a6a13f73a77f91491c/a89ca/universalaim.jpg 600w","sizes":"(min-width: 600px) 600px, 100vw"},"sources":[{"srcSet":"/c4dm-website/static/6cf2e7126aeb16a6a13f73a77f91491c/c65bc/universalaim.webp 150w,\n/c4dm-website/static/6cf2e7126aeb16a6a13f73a77f91491c/078c3/universalaim.webp 300w,\n/c4dm-website/static/6cf2e7126aeb16a6a13f73a77f91491c/6d09e/universalaim.webp 600w","type":"image/webp","sizes":"(min-width: 600px) 600px, 100vw"}]},"width":600,"height":600}}},"status":"active","tags":null,"title":"Deep learning and multi-modal models for the music industry","author":"Dr George Fazekas (PI)","begin":"2019","end":"2023","grant":"AIM CDT PhD studentship","amount":"£54,000 ","link":"https://www.aim.qmul.ac.uk/"},"id":"dc44fa3d-b999-52c0-a3fa-d9dd8f683ec1"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#081818","images":{"fallback":{"src":"/c4dm-website/static/ae6313261ee1509b6ab2d8b648883258/d1e09/unsuperviseddetection.jpg","srcSet":"/c4dm-website/static/ae6313261ee1509b6ab2d8b648883258/d42e7/unsuperviseddetection.jpg 362w,\n/c4dm-website/static/ae6313261ee1509b6ab2d8b648883258/7fb5b/unsuperviseddetection.jpg 724w,\n/c4dm-website/static/ae6313261ee1509b6ab2d8b648883258/d1e09/unsuperviseddetection.jpg 1448w","sizes":"(min-width: 1448px) 1448px, 100vw"},"sources":[{"srcSet":"/c4dm-website/static/ae6313261ee1509b6ab2d8b648883258/38c15/unsuperviseddetection.webp 362w,\n/c4dm-website/static/ae6313261ee1509b6ab2d8b648883258/4eacc/unsuperviseddetection.webp 724w,\n/c4dm-website/static/ae6313261ee1509b6ab2d8b648883258/7c1a3/unsuperviseddetection.webp 1448w","type":"image/webp","sizes":"(min-width: 1448px) 1448px, 100vw"}]},"width":1448,"height":724}}},"status":"active","tags":null,"title":"Unsupervised detection of sound events for complex audio","author":"Dr Emmanouil Benetos (PI), Dr Yanxiong Li (SCUT, CI)","begin":"2021","end":"2023","grant":"Royal Society International Exchanges grant IEC/NSFC/201382","amount":"£3,800","link":"https://royalsociety.org/grants-schemes-awards/grants/international-exchanges/"},"id":"d277b9ec-f5cb-534b-89d8-1d1dadab207f"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#4848a8","images":{"fallback":{"src":"/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/47fd0/rudiments.png","srcSet":"/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/265e7/rudiments.png 150w,\n/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/eb6c9/rudiments.png 300w,\n/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/47fd0/rudiments.png 599w","sizes":"(min-width: 599px) 599px, 100vw"},"sources":[{"srcSet":"/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/7a0a5/rudiments.webp 150w,\n/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/bdee7/rudiments.webp 300w,\n/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/214c6/rudiments.webp 599w","type":"image/webp","sizes":"(min-width: 599px) 599px, 100vw"}]},"width":599,"height":545}}},"status":"complete","tags":["industry"],"title":"Perceptual Aspects of Broadcast Audio Mixing for the Hearing Impaired","author":"Prof Josh Reiss (PI)","begin":"2019","end":"2022","grant":"ICASE PhD studentship 2161145","amount":"£83,300 (standard stipend) + £27,600 (contribution from BBC)","link":"https://gtr.ukri.org/projects?ref=studentship-2161145"},"id":"b0e56d5e-60ea-538c-a7dc-40ed3b0dc194"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/c4dm-website/static/b8946f2bde6c94fa8eeec891e90b1e6b/96aa8/metaphors.png","srcSet":"/c4dm-website/static/b8946f2bde6c94fa8eeec891e90b1e6b/4015f/metaphors.png 93w,\n/c4dm-website/static/b8946f2bde6c94fa8eeec891e90b1e6b/abab1/metaphors.png 185w,\n/c4dm-website/static/b8946f2bde6c94fa8eeec891e90b1e6b/96aa8/metaphors.png 370w","sizes":"(min-width: 370px) 370px, 100vw"},"sources":[{"srcSet":"/c4dm-website/static/b8946f2bde6c94fa8eeec891e90b1e6b/78b69/metaphors.webp 93w,\n/c4dm-website/static/b8946f2bde6c94fa8eeec891e90b1e6b/c5b6a/metaphors.webp 185w,\n/c4dm-website/static/b8946f2bde6c94fa8eeec891e90b1e6b/7fd3d/metaphors.webp 370w","type":"image/webp","sizes":"(min-width: 370px) 370px, 100vw"}]},"width":370,"height":370}}},"status":"complete","tags":null,"title":"Metaphors we listen with: the neural correlates of timbral brightness investigated by pitch-timbre interference and fMRI","author":"Dr Charalampos Saitis (PI), Dr Zachary Wallmark (CI, University of Oregon, US)","begin":"2020","end":"2022","grant":"British Academy, BA/Leverhulme Small Research Grants scheme, SRG1920/101673","amount":"£10,000","link":"http://eecs.qmul.ac.uk/profiles/saitischaralampos.html"},"id":"96ca2677-8048-5074-b2f5-385587b611f8"},{"frontmatter":{"image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#4848a8","images":{"fallback":{"src":"/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/47fd0/rudiments.png","srcSet":"/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/265e7/rudiments.png 150w,\n/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/eb6c9/rudiments.png 300w,\n/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/47fd0/rudiments.png 599w","sizes":"(min-width: 599px) 599px, 100vw"},"sources":[{"srcSet":"/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/7a0a5/rudiments.webp 150w,\n/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/bdee7/rudiments.webp 300w,\n/c4dm-website/static/667dfeac59460a16f71a264dfc9745d7/214c6/rudiments.webp 599w","type":"image/webp","sizes":"(min-width: 599px) 599px, 100vw"}]},"width":599,"height":545}}},"status":"complete","tags":null,"title":"Seeing Music: An interactive digital exhibit on sensory variation and the cross-sensory experience of music","author":"Dr Charalampos Saitis (PI), Dr Christine Cuskley (Newcastle, CI)","begin":"2021","end":"2022","grant":"QMUL Centre for Public Engagement Large Grant","amount":"£9,783","link":"https://www.seeingmusic.app/"},"id":"ce64ac76-ecbc-5a07-a3e4-5713e2a6f9c1"}]},"allTags":{"group":[{"fieldValue":"academic","totalCount":4},{"fieldValue":"industry","totalCount":3}]}}}